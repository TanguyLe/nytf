{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import datetime, time\n",
    "import random\n",
    "from importlib import reload\n",
    "from math import sqrt\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "module_paths = {os.pardir}  # package directory\n",
    "sys.path.extend(module_paths.difference(sys.path))\n",
    "\n",
    "\n",
    "from nytf import utils; reload(utils)\n",
    "#from nytf import main_pipeline; reload(main_pipeline)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 14s, sys: 1min 13s, total: 6min 27s\n",
      "Wall time: 6min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = utils.load_dataframe('train')#, cloud=False)\n",
    "train = pd.concat((train, utils.BasicTemporalFeatures().transform(train)), axis=1)\n",
    "\n",
    "#with open(os.path.join(utils.PROCESSING_DIRECTORY, 'train_basic_features.pkl'), 'rb') as f:\n",
    "#    train = pickle.load(f)\n",
    "\n",
    "test = utils.load_dataframe('test')#, cloud=False)\n",
    "test = pd.concat((test, utils.BasicTemporalFeatures().transform(test)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.402749"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.memory_usage().sum()/10**9  # In Go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.94 s, sys: 391 ms, total: 7.33 s\n",
      "Wall time: 7.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N = 200000\n",
    "ind = sorted(random.sample(range(train.shape[0]), N))\n",
    "X = train.iloc[ind][['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'passenger_count',\n",
    "           'timestamp', 'week_progress_cos', 'week_progress_sin', 'month_progress_cos', 'month_progress_sin',\n",
    "           'year_progress_cos', 'year_progress_sin', 'day_progress_cos', 'day_progress_sin']].values\n",
    "y = train.iloc[ind]['fare_amount'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 17s, sys: 0 ns, total: 1min 17s\n",
      "Wall time: 1min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error : 1.5772289366331023\n",
      "Test error : 3.753414093080567\n",
      "CPU times: user 3.7 s, sys: 0 ns, total: 3.7 s\n",
      "Wall time: 3.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_train_est = regr.predict(X_train).clip(0, 100)\n",
    "print('Train error :', sqrt(((y_train_est - y_train) ** 2).mean()))\n",
    "y_test_est = regr.predict(X_test).clip(0, 100)\n",
    "print('Test error :', sqrt(((y_test_est - y_test) ** 2).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.5 s, sys: 47.1 s, total: 1min 7s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = train[['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'passenger_count',\n",
    "           'timestamp', 'week_progress_cos', 'week_progress_sin', 'month_progress_cos', 'month_progress_sin',\n",
    "           'year_progress_cos', 'year_progress_sin', 'day_progress_cos', 'day_progress_sin']].values\n",
    "y = train['fare_amount'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.05)\n",
    "X = scaler.fit_transform(X)\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(y_true, y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation=lambda tensor: tf.keras.activations.relu(tensor, max_value=100)))\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.01), loss='mse', metrics=[rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54027490/54027490 [==============================] - 140s 3us/step - loss: 69.0168 - rmse: 7.8576\n",
      "Epoch 2/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 19.6326 - rmse: 4.4256\n",
      "Epoch 3/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 16.8208 - rmse: 4.1010\n",
      "Epoch 4/100\n",
      "54027490/54027490 [==============================] - 139s 3us/step - loss: 16.2506 - rmse: 4.0311\n",
      "Epoch 5/100\n",
      "54027490/54027490 [==============================] - 140s 3us/step - loss: 15.9815 - rmse: 3.9976\n",
      "Epoch 6/100\n",
      "54027490/54027490 [==============================] - 140s 3us/step - loss: 15.7828 - rmse: 3.9726\n",
      "Epoch 7/100\n",
      "54027490/54027490 [==============================] - 139s 3us/step - loss: 15.5852 - rmse: 3.9477\n",
      "Epoch 8/100\n",
      "54027490/54027490 [==============================] - 140s 3us/step - loss: 15.3982 - rmse: 3.9239\n",
      "Epoch 9/100\n",
      "54027490/54027490 [==============================] - 140s 3us/step - loss: 15.2565 - rmse: 3.9058\n",
      "Epoch 10/100\n",
      "54027490/54027490 [==============================] - 141s 3us/step - loss: 15.1262 - rmse: 3.8891\n",
      "Epoch 11/100\n",
      "54027490/54027490 [==============================] - 139s 3us/step - loss: 14.9940 - rmse: 3.8721\n",
      "Epoch 12/100\n",
      "54027490/54027490 [==============================] - 140s 3us/step - loss: 14.8809 - rmse: 3.8575\n",
      "Epoch 13/100\n",
      "54027490/54027490 [==============================] - 140s 3us/step - loss: 14.7891 - rmse: 3.8455\n",
      "Epoch 14/100\n",
      "54027490/54027490 [==============================] - 140s 3us/step - loss: 14.7097 - rmse: 3.8352\n",
      "Epoch 15/100\n",
      "54027490/54027490 [==============================] - 140s 3us/step - loss: 14.6275 - rmse: 3.8245\n",
      "Epoch 16/100\n",
      "54027490/54027490 [==============================] - 140s 3us/step - loss: 14.5460 - rmse: 3.8138\n",
      "Epoch 17/100\n",
      "54027490/54027490 [==============================] - 140s 3us/step - loss: 14.4689 - rmse: 3.8037\n",
      "Epoch 18/100\n",
      "54027490/54027490 [==============================] - 141s 3us/step - loss: 14.4147 - rmse: 3.7965\n",
      "Epoch 19/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 14.3061 - rmse: 3.7822\n",
      "Epoch 20/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 14.2352 - rmse: 3.7728\n",
      "Epoch 21/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 14.1609 - rmse: 3.7630\n",
      "Epoch 22/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 14.0990 - rmse: 3.7547\n",
      "Epoch 23/100\n",
      "54027490/54027490 [==============================] - 139s 3us/step - loss: 13.9928 - rmse: 3.7405\n",
      "Epoch 24/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 13.9202 - rmse: 3.7308\n",
      "Epoch 25/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 13.8809 - rmse: 3.7255\n",
      "Epoch 26/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 13.8234 - rmse: 3.7178\n",
      "Epoch 27/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 13.3060 - rmse: 3.6473\n",
      "Epoch 28/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 12.9840 - rmse: 3.6032\n",
      "Epoch 29/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 12.9313 - rmse: 3.5959\n",
      "Epoch 30/100\n",
      "54027490/54027490 [==============================] - 140s 3us/step - loss: 12.8987 - rmse: 3.5914\n",
      "Epoch 31/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 12.8905 - rmse: 3.5902\n",
      "Epoch 32/100\n",
      "54027490/54027490 [==============================] - 140s 3us/step - loss: 12.8391 - rmse: 3.5831\n",
      "Epoch 33/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 12.8392 - rmse: 3.5830\n",
      "Epoch 34/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 12.7479 - rmse: 3.5703\n",
      "Epoch 35/100\n",
      "54027490/54027490 [==============================] - 135s 2us/step - loss: 12.7819 - rmse: 3.5750\n",
      "Epoch 36/100\n",
      "54027490/54027490 [==============================] - 136s 3us/step - loss: 12.6776 - rmse: 3.5604\n",
      "Epoch 37/100\n",
      "54027490/54027490 [==============================] - 140s 3us/step - loss: 12.6917 - rmse: 3.5624\n",
      "Epoch 38/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 12.6339 - rmse: 3.5543\n",
      "Epoch 39/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 12.5977 - rmse: 3.5492\n",
      "Epoch 40/100\n",
      "54027490/54027490 [==============================] - 136s 3us/step - loss: 12.6152 - rmse: 3.5517\n",
      "Epoch 41/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 12.5530 - rmse: 3.5429\n",
      "Epoch 42/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 12.5010 - rmse: 3.5355\n",
      "Epoch 43/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 12.5482 - rmse: 3.5422\n",
      "Epoch 44/100\n",
      "54027490/54027490 [==============================] - 139s 3us/step - loss: 12.5016 - rmse: 3.5356\n",
      "Epoch 45/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 12.4397 - rmse: 3.5269\n",
      "Epoch 46/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 12.4533 - rmse: 3.5288\n",
      "Epoch 47/100\n",
      "54027490/54027490 [==============================] - 136s 3us/step - loss: 12.4269 - rmse: 3.5251\n",
      "Epoch 48/100\n",
      "54027490/54027490 [==============================] - 139s 3us/step - loss: 12.3884 - rmse: 3.5196\n",
      "Epoch 49/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 12.3913 - rmse: 3.5200\n",
      "Epoch 50/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 12.3992 - rmse: 3.5211\n",
      "Epoch 51/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 12.3116 - rmse: 3.5087\n",
      "Epoch 52/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 12.1324 - rmse: 3.4830\n",
      "Epoch 53/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 12.1295 - rmse: 3.4826\n",
      "Epoch 54/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 12.0351 - rmse: 3.4690\n",
      "Epoch 55/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 12.0671 - rmse: 3.4736\n",
      "Epoch 56/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 12.0298 - rmse: 3.4683\n",
      "Epoch 57/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.9993 - rmse: 3.4639\n",
      "Epoch 58/100\n",
      "54027490/54027490 [==============================] - 136s 3us/step - loss: 11.9992 - rmse: 3.4639\n",
      "Epoch 59/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 11.9277 - rmse: 3.4535\n",
      "Epoch 60/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.9345 - rmse: 3.4545\n",
      "Epoch 61/100\n",
      "54027490/54027490 [==============================] - 141s 3us/step - loss: 11.8802 - rmse: 3.4466\n",
      "Epoch 62/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 11.8744 - rmse: 3.4458\n",
      "Epoch 63/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.8542 - rmse: 3.4429\n",
      "Epoch 64/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.8377 - rmse: 3.4405\n",
      "Epoch 65/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 11.8236 - rmse: 3.4384\n",
      "Epoch 66/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 11.8355 - rmse: 3.4401\n",
      "Epoch 67/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.8243 - rmse: 3.4385\n",
      "Epoch 68/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 11.7863 - rmse: 3.4330\n",
      "Epoch 69/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.8184 - rmse: 3.4376\n",
      "Epoch 70/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.7570 - rmse: 3.4287\n",
      "Epoch 71/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 11.8044 - rmse: 3.4356\n",
      "Epoch 72/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 11.7533 - rmse: 3.4282\n",
      "Epoch 73/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.8259 - rmse: 3.4387\n",
      "Epoch 74/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.7462 - rmse: 3.4271\n",
      "Epoch 75/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.7383 - rmse: 3.4260\n",
      "Epoch 76/100\n",
      "54027490/54027490 [==============================] - 135s 3us/step - loss: 11.7565 - rmse: 3.4286\n",
      "Epoch 77/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.7412 - rmse: 3.4264\n",
      "Epoch 78/100\n",
      "54027490/54027490 [==============================] - 136s 3us/step - loss: 11.7251 - rmse: 3.4241\n",
      "Epoch 79/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.7510 - rmse: 3.4278\n",
      "Epoch 80/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 11.7241 - rmse: 3.4239\n",
      "Epoch 81/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.7206 - rmse: 3.4234\n",
      "Epoch 82/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.7396 - rmse: 3.4262\n",
      "Epoch 83/100\n",
      "54027490/54027490 [==============================] - 136s 3us/step - loss: 11.7194 - rmse: 3.4232\n",
      "Epoch 84/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.6956 - rmse: 3.4198\n",
      "Epoch 85/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.7179 - rmse: 3.4230\n",
      "Epoch 86/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 11.7284 - rmse: 3.4245\n",
      "Epoch 87/100\n",
      "54027490/54027490 [==============================] - 138s 3us/step - loss: 11.6912 - rmse: 3.4191\n",
      "Epoch 88/100\n",
      "54027490/54027490 [==============================] - 136s 3us/step - loss: 11.6935 - rmse: 3.4195\n",
      "Epoch 89/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.7231 - rmse: 3.4237\n",
      "Epoch 90/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.6701 - rmse: 3.4160\n",
      "Epoch 91/100\n",
      "54027490/54027490 [==============================] - 139s 3us/step - loss: 11.6891 - rmse: 3.4188\n",
      "Epoch 92/100\n",
      "54027490/54027490 [==============================] - 136s 3us/step - loss: 11.6725 - rmse: 3.4164\n",
      "Epoch 93/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.6892 - rmse: 3.4188\n",
      "Epoch 94/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.6819 - rmse: 3.4178\n",
      "Epoch 95/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.6794 - rmse: 3.4174\n",
      "Epoch 96/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.6418 - rmse: 3.4119\n",
      "Epoch 97/100\n",
      "54027490/54027490 [==============================] - 136s 3us/step - loss: 11.6427 - rmse: 3.4120\n",
      "Epoch 98/100\n",
      "54027490/54027490 [==============================] - 136s 3us/step - loss: 11.6536 - rmse: 3.4136\n",
      "Epoch 99/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.6577 - rmse: 3.4142\n",
      "Epoch 100/100\n",
      "54027490/54027490 [==============================] - 137s 3us/step - loss: 11.6419 - rmse: 3.4119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f33c3243550>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=100, batch_size=2**20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  240       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  528       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  272       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  17        \n",
      "=================================================================\n",
      "Total params: 1,601\n",
      "Trainable params: 1,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/matplotlib/font_manager.py:1320: UserWarning: findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f33c001f400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test = test[['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'passenger_count',\n",
    "           'timestamp', 'week_progress_cos', 'week_progress_sin', 'month_progress_cos', 'month_progress_sin',\n",
    "           'year_progress_cos', 'year_progress_sin', 'day_progress_cos', 'day_progress_sin']].values\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "plt.hist(y_test_pred, bins=200)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['fare_amount'] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('first_neural_network.csv', index=False, columns=['key', 'fare_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
