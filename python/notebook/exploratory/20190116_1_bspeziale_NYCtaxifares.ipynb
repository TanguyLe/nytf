{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW YORK CITY TAXI FARES (NYCTF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project imports, folders and variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/env35/lib/python3.5/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['isclose', 'fabs', 'log', 'copysign', 'nan', 'expm1', 'log2', 'log10', 'floor', 'modf', 'fmod', 'trunc', 'sin', 'cos', 'tan', 'isnan', 'isinf', 'tanh', 'hypot', 'ceil', 'isfinite', 'radians', 'sinh', 'inf', 'e', 'log1p', 'sqrt', 'pi', 'gamma', 'cosh', 'ldexp', 'frexp', 'degrees', 'exp', 'gcd']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from math import *\n",
    "\n",
    "#pyplot\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "#dealing with folder paths\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#serialisation and compression\n",
    "import pickle\n",
    "\n",
    "#refreshing modules imports\n",
    "from importlib import reload\n",
    "\n",
    "#display images\n",
    "import IPython\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = os.path.join(os.getcwd(), os.pardir, os.pardir, os.pardir)\n",
    "#notebook is in \"NYCTF/python/notebooks/exploratory\" or \"NYCTF/python/notebooks/reports\": this actually links to NYCTF\n",
    "\n",
    "src_dir = os.path.join(project_dir, 'python/nytf')\n",
    "sys.path.append(src_dir) #adds src to search path for modules\n",
    "\n",
    "data_dir = os.path.join(project_dir, 'data')\n",
    "pickle_dir = os.path.join(data_dir, 'processed/pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "global dist_unit\n",
    "dist_unit = 'km'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nytf_data_preparation as dp; reload(dp);\n",
    "import nytf_geo as geo; reload(geo);\n",
    "import nytf_geo_extractor as geo_extractor; reload(geo_extractor);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_use_pickle_files = True\n",
    "#True should you want to use the data stored using pickle\n",
    "#False should you want to (re)generate the data from scratch\n",
    "\n",
    "b_data_prepared = False\n",
    "#True if the loaded data are already prepared\n",
    "#False if the loaded data are raw\n",
    "\n",
    "readcsv_parse_dates = False\n",
    "#only matters if usePickleFiles is set to False\n",
    "#[\"pickup_datetime\"] should you want to parse dates when reading the csv file\n",
    "#False shoud you want to do it later (manually)\n",
    "\n",
    "minmax_coordinates = [40.568973, 41.709555, -74.263242, -72.986532]\n",
    "#[latitude min, latitude max, longitude min, longitude max]\n",
    "#needs some more exploration and thinking. for now: extrema in training set for both pickup and dropoff locations\n",
    "\n",
    "col_types = {'fare_amount': 'float32', #tried float16 but then you cannot calculate the mean and std\n",
    "             'pickup_longitude': 'float32',\n",
    "             'pickup_latitude': 'float32',\n",
    "             'dropoff_longitude': 'float32',\n",
    "             'dropoff_latitude': 'float32',\n",
    "             'passenger_count': 'uint8'}\n",
    "\n",
    "r_earth = 6371 #radius of the Earth in dist_unit\n",
    "\n",
    "b_display_math_demo = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading & preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get number of lines in the csv files (if loading from csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and test datasets will not come from .csv files.\n",
      "CPU times: user 66 µs, sys: 34 µs, total: 100 µs\n",
      "Wall time: 82 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#choose method among 'unixwc' and 'readlines'. 'readlines' (resp. 'unixwc') faster for short (resp. long) files\n",
    "method = 'readlines'\n",
    "\n",
    "if not b_use_pickle_files:\n",
    "    train_row_count = dp.row_count(os.path.join(data_dir, 'raw/train.csv'), method)\n",
    "    test_row_count = dp.row_count(os.path.join(data_dir, 'raw/test.csv'), method)\n",
    "    print('Number of lines in train file: ' + str(train_row_count))\n",
    "    print('Number of lines in test file: ' + str(test_row_count))\n",
    "else:\n",
    "    print('Training and test datasets will not come from .csv files.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data (from csv or pickle files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.4 s, sys: 9.35 s, total: 25.7 s\n",
      "Wall time: 28.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if b_use_pickle_files:\n",
    "    if b_data_prepared:\n",
    "        with open(os.path.join(data_dir, 'processed/pickle/train_prep.pickle'), 'rb') as f:\n",
    "            df_train_prep = pickle.load(f)\n",
    "        with open(os.path.join(data_dir, 'processed/pickle/test_prep.pickle'), 'rb') as f:\n",
    "            df_test_prep = pickle.load(f)\n",
    "    else:\n",
    "        with open(os.path.join(data_dir, 'processed/pickle/train.pickle'), 'rb') as f:\n",
    "            df_train = pickle.load(f)\n",
    "        with open(os.path.join(data_dir, 'processed/pickle/test.pickle'), 'rb') as f:\n",
    "            df_test = pickle.load(f)\n",
    "else:\n",
    "    df_train = pd.read_csv(os.path.join(data_dir, 'raw/train.csv'), parse_dates=readcsv_parse_dates)\n",
    "    df_test = pd.read_csv(os.path.join(data_dir, 'raw/test.csv'), parse_dates=readcsv_parse_dates)\n",
    "    with open(os.path.join(data_dir, 'processed/pickle/train.pickle'), 'wb') as f:\n",
    "        pickle.dump(df_train, f)\n",
    "    with open(os.path.join(data_dir, 'processed/pickle/test.pickle'), 'wb') as f:\n",
    "        pickle.dump(df_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Step 1/7 complete.\n",
      "Step 2/7 skipped. Not a training set.\n",
      "Step 3/7 skipped. Not a training set.\n",
      "Step 4/7 complete. Dates have been parsed.\n",
      "Step 5/7 skipped. Not a training set.\n",
      "Step 6/7 complete. Indexes reset.\n",
      "Step 7/7 complete. Prepared dataframe has been saved in a pickle file.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9914 entries, 0 to 9913\n",
      "Data columns (total 7 columns):\n",
      "key                  9914 non-null object\n",
      "pickup_datetime      9914 non-null datetime64[ns, UTC]\n",
      "pickup_longitude     9914 non-null float32\n",
      "pickup_latitude      9914 non-null float32\n",
      "dropoff_longitude    9914 non-null float32\n",
      "dropoff_latitude     9914 non-null float32\n",
      "passenger_count      9914 non-null uint8\n",
      "dtypes: datetime64[ns, UTC](1), float32(4), object(1), uint8(1)\n",
      "memory usage: 319.6+ KB\n",
      "None\n",
      "CPU times: user 26.1 ms, sys: 2.88 ms, total: 29 ms\n",
      "Wall time: 31.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not b_data_prepared:\n",
    "    df_test_prep = dp.prepare_data(df_test, 'test', col_types, readcsv_parse_dates==False, True, pickle_dir, 'test_prep.pickle')\n",
    "    print(df_test_prep.info())\n",
    "else:\n",
    "    print('Data already prepared.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Step 1/7 complete.\n",
      "Step 2/7 complete. Incomplete rows have been removed.\n",
      "Step 3/7 complete. Types changed to more relevant ones.\n",
      "Step 4/7 complete. Dates have been parsed.\n",
      "Step 5/7 complete. Records with negative or >=$1000 fares have been removed.\n",
      "Step 6/7 complete. Indexes reset.\n",
      "Step 7/7 complete. Prepared dataframe has been saved in a pickle file.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55419634 entries, 0 to 55419633\n",
      "Data columns (total 8 columns):\n",
      "key                  object\n",
      "fare_amount          float32\n",
      "pickup_datetime      datetime64[ns, UTC]\n",
      "pickup_longitude     float32\n",
      "pickup_latitude      float32\n",
      "dropoff_longitude    float32\n",
      "dropoff_latitude     float32\n",
      "passenger_count      uint8\n",
      "dtypes: datetime64[ns, UTC](1), float32(5), object(1), uint8(1)\n",
      "memory usage: 1.9+ GB\n",
      "None\n",
      "CPU times: user 1min 57s, sys: 24.7 s, total: 2min 21s\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not b_data_prepared:\n",
    "    df_train_prep = dp.prepare_data(df_train, 'Train', col_types, readcsv_parse_dates==False, True, pickle_dir, 'train_prep.pickle')\n",
    "    print(df_train_prep.info())\n",
    "else:\n",
    "    print('Data already prepared.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geo (cleaning + first ideas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_prep_geo = df_train_prep.copy(False)\n",
    "df_test_prep_geo = df_test_prep.copy(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55423856"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.44 s, sys: 3.25 s, total: 7.7 s\n",
      "Wall time: 7.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Remove outlying coordinates\n",
    "df_train_prep_geo = geo.remove_outlying_coordinates(df_train_prep_geo, minmax_coordinates)\n",
    "df_train_prep_geo = df_train_prep_geo.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54234152"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_prep_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 ms, sys: 0 ns, total: 10.5 ms\n",
      "Wall time: 9.76 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_test_prep_geo = geo.remove_outlying_coordinates(df_test_prep_geo, minmax_coordinates)\n",
    "df_test_prep_geo = df_test_prep_geo.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a 'distance' feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First method is flying distance.\n",
    "Second method consists in rotating the map of Manhattan then using the 1-distance.\n",
    "Third method consists of using Google Maps (or similar) - the itinerary may however not be the one the taxi driver actually took."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if b_display_math_demo:\n",
    "    display(Image(os.path.join(data_dir, 'processed/images/sphere.jpg')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flying distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if b_display_math_demo:\n",
    "    display(Image(os.path.join(data_dir, 'processed/images/flying_distance.JPG')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 43s, sys: 3.9 s, total: 1min 47s\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train_prep_geo = geo.add_flying_distance(df_train_prep_geo, 'deg', r_earth, dist_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.1 ms, sys: 457 µs, total: 34.6 ms\n",
      "Wall time: 33.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_test_prep_geo = geo.add_flying_distance(df_test_prep_geo, 'deg', r_earth, dist_unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1-distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle: -0.5007080588399464 rad = -28.68845853971702°.\n"
     ]
    }
   ],
   "source": [
    "#Calculating the angle of which the Manhattan street grid is rotated from the north-south axis\n",
    "#https://www.nytimes.com/2006/07/02/nyregion/thecity/02grid.html states 29°. Let us check this.\n",
    "if b_display_math_demo:\n",
    "    display(Image(os.path.join(data_dir, 'processed/images/Manhattan_street_angle.png')))\n",
    "\n",
    "l_man = 197\n",
    "h_man = 360\n",
    "ang_man = - atan(l_man/h_man) #angle de rotation du repère (rad), et non de la map (opposé)\n",
    "print('Angle: ' + str(ang_man) +' rad = ' + str(ang_man*180/pi) + '°.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "if b_display_math_demo:\n",
    "    display(Image(os.path.join(data_dir, 'processed/images/L1_distance_1.JPG')))\n",
    "    display(Image(os.path.join(data_dir, 'processed/images/L1_distance_2.JPG')))\n",
    "    display(Image(os.path.join(data_dir, 'processed/images/L1_distance_3.JPG')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 42s, sys: 5min 37s, total: 24min 20s\n",
      "Wall time: 18min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train_prep_geo = geo.add_L1_distance(df_train_prep_geo, 'deg', r_earth, dist_unit, ang_man) #plane_rot_angle in rad please"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 228 ms, sys: 56.1 ms, total: 284 ms\n",
      "Wall time: 204 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_test_prep_geo = geo.add_L1_distance(df_test_prep_geo, 'deg', r_earth, dist_unit, ang_man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'processed/pickle/train_prep_geo.pickle'), 'wb') as f:\n",
    "        pickle.dump(df_train_prep_geo, f)\n",
    "with open(os.path.join(data_dir, 'processed/pickle/test_prep_geo.pickle'), 'wb') as f:\n",
    "        pickle.dump(df_test_prep_geo, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'processed/pickle/train_prep_geo.pickle'), 'rb') as f:\n",
    "            df_train_prep_geo = pickle.load(f)\n",
    "with open(os.path.join(data_dir, 'processed/pickle/test_prep_geo.pickle'), 'rb') as f:\n",
    "            df_test_prep_geo = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>flying_distance_km</th>\n",
       "      <th>L1_distance_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-06-15 17:26:21.0000001</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-06-15 17:26:00+00:00</td>\n",
       "      <td>-73.844315</td>\n",
       "      <td>40.721317</td>\n",
       "      <td>-73.841614</td>\n",
       "      <td>40.712276</td>\n",
       "      <td>1</td>\n",
       "      <td>1.030742</td>\n",
       "      <td>1.274083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05 16:52:16.0000002</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2010-01-05 16:52:00+00:00</td>\n",
       "      <td>-74.016045</td>\n",
       "      <td>40.711304</td>\n",
       "      <td>-73.979271</td>\n",
       "      <td>40.782005</td>\n",
       "      <td>1</td>\n",
       "      <td>8.450000</td>\n",
       "      <td>9.440086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-08-18 00:35:00.00000049</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2011-08-18 00:35:00+00:00</td>\n",
       "      <td>-73.982735</td>\n",
       "      <td>40.761269</td>\n",
       "      <td>-73.991241</td>\n",
       "      <td>40.750561</td>\n",
       "      <td>2</td>\n",
       "      <td>1.389632</td>\n",
       "      <td>1.445443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-04-21 04:30:42.0000001</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2012-04-21 04:30:00+00:00</td>\n",
       "      <td>-73.987129</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991570</td>\n",
       "      <td>40.758091</td>\n",
       "      <td>1</td>\n",
       "      <td>2.799211</td>\n",
       "      <td>3.616691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-03-09 07:51:00.000000135</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2010-03-09 07:51:00+00:00</td>\n",
       "      <td>-73.968094</td>\n",
       "      <td>40.768009</td>\n",
       "      <td>-73.956657</td>\n",
       "      <td>40.783764</td>\n",
       "      <td>1</td>\n",
       "      <td>1.999081</td>\n",
       "      <td>2.002912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011-01-06 09:50:45.0000002</td>\n",
       "      <td>12.1</td>\n",
       "      <td>2011-01-06 09:50:00+00:00</td>\n",
       "      <td>-74.000961</td>\n",
       "      <td>40.731628</td>\n",
       "      <td>-73.972893</td>\n",
       "      <td>40.758232</td>\n",
       "      <td>1</td>\n",
       "      <td>3.787118</td>\n",
       "      <td>4.384430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012-11-20 20:35:00.0000001</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2012-11-20 20:35:00+00:00</td>\n",
       "      <td>-73.980003</td>\n",
       "      <td>40.751663</td>\n",
       "      <td>-73.973801</td>\n",
       "      <td>40.764843</td>\n",
       "      <td>1</td>\n",
       "      <td>1.555860</td>\n",
       "      <td>1.781619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012-01-04 17:22:00.00000081</td>\n",
       "      <td>16.5</td>\n",
       "      <td>2012-01-04 17:22:00+00:00</td>\n",
       "      <td>-73.951302</td>\n",
       "      <td>40.774139</td>\n",
       "      <td>-73.990097</td>\n",
       "      <td>40.751049</td>\n",
       "      <td>1</td>\n",
       "      <td>4.155500</td>\n",
       "      <td>5.454634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2012-12-03 13:10:00.000000125</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2012-12-03 13:10:00+00:00</td>\n",
       "      <td>-74.006462</td>\n",
       "      <td>40.726711</td>\n",
       "      <td>-73.993080</td>\n",
       "      <td>40.731628</td>\n",
       "      <td>1</td>\n",
       "      <td>1.253181</td>\n",
       "      <td>1.747667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2009-09-02 01:11:00.00000083</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2009-09-02 01:11:00+00:00</td>\n",
       "      <td>-73.980659</td>\n",
       "      <td>40.733871</td>\n",
       "      <td>-73.991539</td>\n",
       "      <td>40.758137</td>\n",
       "      <td>2</td>\n",
       "      <td>2.849590</td>\n",
       "      <td>3.298166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             key  fare_amount           pickup_datetime  \\\n",
       "0    2009-06-15 17:26:21.0000001          4.5 2009-06-15 17:26:00+00:00   \n",
       "1    2010-01-05 16:52:16.0000002         16.9 2010-01-05 16:52:00+00:00   \n",
       "2   2011-08-18 00:35:00.00000049          5.7 2011-08-18 00:35:00+00:00   \n",
       "3    2012-04-21 04:30:42.0000001          7.7 2012-04-21 04:30:00+00:00   \n",
       "4  2010-03-09 07:51:00.000000135          5.3 2010-03-09 07:51:00+00:00   \n",
       "5    2011-01-06 09:50:45.0000002         12.1 2011-01-06 09:50:00+00:00   \n",
       "6    2012-11-20 20:35:00.0000001          7.5 2012-11-20 20:35:00+00:00   \n",
       "7   2012-01-04 17:22:00.00000081         16.5 2012-01-04 17:22:00+00:00   \n",
       "8  2012-12-03 13:10:00.000000125          9.0 2012-12-03 13:10:00+00:00   \n",
       "9   2009-09-02 01:11:00.00000083          8.9 2009-09-02 01:11:00+00:00   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.844315        40.721317         -73.841614         40.712276   \n",
       "1        -74.016045        40.711304         -73.979271         40.782005   \n",
       "2        -73.982735        40.761269         -73.991241         40.750561   \n",
       "3        -73.987129        40.733143         -73.991570         40.758091   \n",
       "4        -73.968094        40.768009         -73.956657         40.783764   \n",
       "5        -74.000961        40.731628         -73.972893         40.758232   \n",
       "6        -73.980003        40.751663         -73.973801         40.764843   \n",
       "7        -73.951302        40.774139         -73.990097         40.751049   \n",
       "8        -74.006462        40.726711         -73.993080         40.731628   \n",
       "9        -73.980659        40.733871         -73.991539         40.758137   \n",
       "\n",
       "   passenger_count  flying_distance_km  L1_distance_km  \n",
       "0                1            1.030742        1.274083  \n",
       "1                1            8.450000        9.440086  \n",
       "2                2            1.389632        1.445443  \n",
       "3                1            2.799211        3.616691  \n",
       "4                1            1.999081        2.002912  \n",
       "5                1            3.787118        4.384430  \n",
       "6                1            1.555860        1.781619  \n",
       "7                1            4.155500        5.454634  \n",
       "8                1            1.253181        1.747667  \n",
       "9                2            2.849590        3.298166  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_prep_geo.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographical clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 cluster would be, for example, the JFK airport, or a \"neighbourhood\" in NYC (maybe not the official ones, can be customised/calculated zones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time (first ideas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time clusters / geo-time clusters / time-related features?\n",
    "\n",
    "#weekday/WE, night, rushhour, before/after 201X when they changed the fares...: all those that impact the fare directly through surchages\n",
    "#these should not be geo-dependent\n",
    "\n",
    "#some other time-related paramaters/clusters might be geo-dependent (id est impact the traffic situation)\n",
    "\n",
    "#---\n",
    "#Estimate the duration of the trip?\n",
    "\n",
    "#---\n",
    "#Open data...?\n",
    "\n",
    "#Weather data, traffic data...?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
